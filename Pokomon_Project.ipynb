{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokomon_Project",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPp1tzrp/3xudosdM5wRXx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gold999-lgtm/Project1/blob/main/Pokomon_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF0Yuzgjq5Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ace5c1-105a-402a-dd3d-9399a9b9d03d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLnIVufNr-3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89b6e96-5a24-4acf-a5a0-70e5ce12fa94"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7NxNDvatUPR"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyaWlBhxuwJc"
      },
      "source": [
        "classifier=Sequential()\n",
        "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "classifier.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units=128,activation=\"relu\"))\n",
        "classifier.add(Dense(units=3,activation=\"softmax\"))\n",
        "classifier.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLMt9dt5wKG2",
        "outputId": "42600a34-bb5e-46c3-bf8a-4cc0d3c704cd"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 shear_range=0.2,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1.0/255)\n",
        "training_set=train_datagen.flow_from_directory(\"/content/drive/My Drive/dataset/training_set\",\n",
        "                                               target_size=(64,64),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")\n",
        "test_set=test_datagen.flow_from_directory(\"/content/drive/My Drive/dataset/test_set\",\n",
        "                                               target_size=(64,64),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 445 images belonging to 3 classes.\n",
            "Found 238 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCerwSIfxrLb",
        "outputId": "b1e99965-5686-44ab-bbda-2d78c85c5e32"
      },
      "source": [
        "print(type(training_set))\n",
        "print(type(train_datagen))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'keras.preprocessing.image.DirectoryIterator'>\n",
            "<class 'keras.preprocessing.image.ImageDataGenerator'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNOTKO0Axznt",
        "outputId": "f019d6d9-4858-4bba-9a7a-2311a57e91c9"
      },
      "source": [
        "history=classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=100,\n",
        "                         epochs=5,\n",
        "                         validation_data=test_set,\n",
        "                         validation_steps=200)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 10/100 [==>...........................] - ETA: 1:53 - loss: 1.0009 - accuracy: 0.5156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 14/100 [===>..........................] - ETA: 1:40 - loss: 0.8787 - accuracy: 0.5978WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 28s 267ms/step - loss: 0.8787 - accuracy: 0.5978 - val_loss: 0.6085 - val_accuracy: 0.8151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBP7oSn-zHXr",
        "outputId": "8002c75b-c8b3-4ab2-dd00-6d5a03cad79a"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img(\"/content/drive/My Drive/balbasaur.png\",target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "predictions=classifier.predict(test_image)\n",
        "print(training_set.class_indices)\n",
        "print((predictions>0.5).astype(\"int32\"))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bulbasaur': 0, 'charmander': 1, 'pikachu': 2}\n",
            "[[1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2I3CrTy17br"
      },
      "source": [
        "import keras\n",
        "from keras.applications.vgg16 import VGG16\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ISDxkB31H2"
      },
      "source": [
        "conv_base=VGG16(weights=\"imagenet\",include_top=False,input_shape=(150,150,3))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHkzVdwg9BeM",
        "outputId": "afff685f-8d62-41a1-8659-3b694c123721"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33YvNxPZ5FG3"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "import os\n",
        "model=models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256,activation=\"relu\"))\n",
        "model.add(layers.Dense(3,activation=\"softmax\"))"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnTpFsq25si8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4995b151-90b5-4ea7-a25a-ef0d3bf929d1"
      },
      "source": [
        "conv_base.trainable=False\n",
        "conv_base.summary()\n",
        "model.summary()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,812,867\n",
            "Trainable params: 2,098,179\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2nhiF_a5t0f"
      },
      "source": [
        "base_dir=\"/content/drive/My Drive/dataset/\"\n",
        "train_dir=os.path.join(base_dir,\"training_set\")\n",
        "test_dir=os.path.join(base_dir,\"test_set\")"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XmsVAhD6YgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5a1457-d364-49ce-b387-e375ebbae609"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=40,\n",
        "                                 width_shift_range=0.2,\n",
        "                                 height_shift_range=0.2,\n",
        "                                 shear_range=0.2,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(150,150),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode=\"categorical\")\n",
        "test_generator=test_datagen.flow_from_directory(test_dir,\n",
        "                                                target_size=(150,150),\n",
        "                                                batch_size=20,\n",
        "                                                class_mode=\"categorical\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 238 images belonging to 3 classes.\n",
            "Found 238 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0scQdTw6QxrL",
        "outputId": "a3ef41b6-1d37-470a-cfcc-8849cf2b9aed"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"acc\"])\n",
        "history=model.fit_generator(train_generator,\n",
        "                            steps_per_epoch=100,\n",
        "                            epochs=30,\n",
        "                            validation_data=test_generator,\n",
        "                            validation_steps=50)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 12/100 [==>...........................] - ETA: 7:28 - loss: 3.1072 - acc: 0.4790WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 146s 1s/step - loss: 3.1072 - acc: 0.4790 - val_loss: 2.2925 - val_acc: 0.3445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj6Zf1T7kAo9",
        "outputId": "5229a760-cff9-47bc-f262-aed0ee39f553"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img(\"/content/drive/My Drive/balbasaur.png\",target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "predictions=classifier.predict(test_image)\n",
        "print(training_set.class_indices)\n",
        "print((predictions>0.5).astype(\"int32\"))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bulbasaur': 0, 'charmander': 1, 'pikachu': 2}\n",
            "[[1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BnzCRifRa-H",
        "outputId": "36a63e48-cee2-4d95-f058-b3a62be18db6"
      },
      "source": [
        "conv_base.trainable=True\n",
        "set_trainable=False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name==\"block5_conv1\":\n",
        "    set_trainable=True\n",
        "  if set_trainable:\n",
        "    layer.trainable=True\n",
        "  else:\n",
        "    layer.trainable=False\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"acc\"])\n",
        "history=model.fit_generator(train_generator,\n",
        "                            steps_per_epoch=100,\n",
        "                            epochs=30,\n",
        "                            validation_data=test_generator,\n",
        "                            validation_steps=50)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 12/100 [==>...........................] - ETA: 8:54 - loss: 73.3070 - acc: 0.3529WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 158s 2s/step - loss: 73.3070 - acc: 0.3529 - val_loss: 1.0958 - val_acc: 0.3739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RNyhv_riM9f",
        "outputId": "ae4e3e49-4fbd-4acb-adf0-6eba0808bfc6"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img(\"/content/drive/My Drive/balbasaur.png\",target_size=(150,150))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "predictions=model.predict(test_image)\n",
        "print(training_set.class_indices)\n",
        "print((predictions>0.5).astype(\"int32\"))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bulbasaur': 0, 'charmander': 1, 'pikachu': 2}\n",
            "[[1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYv04dSpjf65"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}